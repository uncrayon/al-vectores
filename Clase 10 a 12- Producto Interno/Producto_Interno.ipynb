{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Producto Interno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *producto interno* (estándar) o simplemente *producto punto* de dos $n$-vectores $\\vec{a},\\vec{b}$ se define como el escalar:\n",
    "\n",
    "$$\n",
    "<\\vec{a},\\vec{b}> = \\vec{a} \\cdot \\vec{b} = a_{0}b_{0}+a_{1}b_{1}+\\cdots+a_{n-1}b_{n-1} = \\displaystyle\\sum_{i=0}^{n-1} a_{i}b_{i}\n",
    "$$\n",
    "\n",
    "Que es simplemente la suma del producto de sus entradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, si $\\vec{a}=(1,2,3)$ y $\\vec{b}=(4,5,6)$ entonces el producto punto será:\n",
    "\n",
    "$$\n",
    "\\vec{a}\\cdot\\vec{b} = (1,2,3)\\cdot (4,5,6) = 1\\cdot 4+2\\cdot 5 + 3\\cdot 6 = 4+10+18=32\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora trabajamos de forma indiferente con *vectores columna* y *vectores renglón*, a partir de este momento **el estándar serán los vectores columna** entonces simpre que hablemos de un vector, dígamos $\\vec{a}$ entonces estaremos hablando del vector columna:\n",
    "\n",
    "$$\n",
    "\\vec{a} = \\begin{bmatrix}a_{0}\\\\ a_{1}\\\\ \\vdots \\\\ a_{n-1}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Esto también nos permite introducir una nueva operación: **la transposición**. Retomemos el vector $\\vec{a}$, denotaremos como $\\vec{a}^{T}$ al vector transpuesto de $\\vec{a}$:\n",
    "\n",
    "$$\n",
    "\\vec{a}^{T} = \\begin{bmatrix}a_{0}\\\\ a_{1}\\\\ \\vdots \\\\ a_{n-1}\\end{bmatrix}^{T} = [a_{0}\\; a_{1}\\; \\cdots \\; a_{n-1}]\n",
    "$$\n",
    "\n",
    "La operación de transposición nos permite cambiar de vectores columna a vectores renglón sin modificar al vector que se transponga. Notemos que es posible poder transponer un vector transpuesto_\n",
    "\n",
    "$$\n",
    "\\left(\\vec{a}^{T}\\right)^{T} = \\left(\\begin{bmatrix}a_{0}\\\\ a_{1}\\\\ \\vdots \\\\ a_{n-1}\\end{bmatrix}^{T}\\right)^{T} = [a_{0}\\; a_{1}\\; \\cdots \\; a_{n-1}]^{T} = \\begin{bmatrix}a_{0}\\\\ a_{1}\\\\ \\vdots \\\\ a_{n-1}\\end{bmatrix} = \\vec{a}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así pues, consideremos el ejemplo anterior de los vectores $\\vec{a}$ y $\\vec{b}$. Definimos la operación $\\vec{a}^{T}\\vec{b}$ como:\n",
    "\n",
    "$$\n",
    "\\vec{a}^{T}\\; \\vec{b} = [a_{0}\\; a_{1}\\; \\cdots \\; a_{n-1}]  \\begin{bmatrix}b_{0}\\\\ b_{1}\\\\ \\vdots \\\\ b_{n-1}\\end{bmatrix} = a_{0}b_{0} + a_{1}b_{1} + \\cdots + a_{n-1}b_{n-1} = \\displaystyle\\sum_{i=0}^{n-1} a_{i}b_{i}\n",
    "$$\n",
    "\n",
    "Lo cual coincide con la definición del producto interno. Así pues $<\\vec{a},\\vec{b}> = \\vec{a}\\cdot \\vec{b} = \\vec{a}^{T} \\;\\vec{b} = \\displaystyle\\sum_{i=0}^{n-1} a_{i}b_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Propiedades del producto interno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sean $\\vec{a},\\vec{b}$ dos $n$-vectores y $\\alpha$ un escalar. El producto interno entre $\\vec{a}$ y $\\vec{b}$ cumple las siguientes propiedades:\n",
    "\n",
    "* Conmutatividad: $\\vec{a}^{T}\\vec{b} = \\displaystyle\\sum_{i=0}^{n-1} a_{i}b_{i} = \\displaystyle\\sum_{i=0}^{n-1} b_{i}a_{i} = \\vec{b}^{T}\\vec{a}$\n",
    "\n",
    "* Asociatividad con multiplicación escalar: $\\left(\\alpha \\vec{a}\\right)^{T}\\vec{b} = \\alpha\\left(\\vec{a}^{T}\\vec{b}\\right)$\n",
    "\n",
    "* Distribución en la adición de vectores: $\\left(\\vec{a} + \\vec{b}\\right)^{T}\\vec{c} = \\vec{a}^{T}\\vec{c} + \\vec{b}^{T}\\vec{c}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Consideraciones adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proyección**. Si $\\vec{a}$ es un $n$-vector entonces $\\hat{e}_{i}^{T}\\vec{a} = a_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suma de elementos de un vector.** $\\mathbf{1}^{T}a = a_{0}+a_{1}+\\cdots+a_{n-1}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Promedio de entradas de un vector.** $(\\mathbf{1}/n)^{T}\\vec{a} = (a_{0}+a_{1}+\\cdots+a_{n-1})/n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suma de cuadrados de un vector.** $\\vec{a}^{T} \\;\\vec{a} = a_{0}^{2}+a_{1}^{2}+\\cdots+a_{n-1}^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Producto interno de bloques de vectores**. Sean $\\vec{a},\\vec{b}$ $k$-vectores formados por concatenar los $n$-vectores $a_{i},b_{i}$:\n",
    "\n",
    "$$\n",
    "\\vec{a}=\\begin{bmatrix}a_{0}\\\\ a_{1}\\\\ \\vdots \\\\ a_{k-1}\\end{bmatrix},\\qquad \\vec{b}=\\begin{bmatrix}b_{0}\\\\ b_{1}\\\\ \\vdots \\\\ b_{k-1}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Entonces el producto punto entre estos vectores va como:\n",
    "\n",
    "$$\n",
    "\\vec{a}^{T} \\vec{b} = [a_{0}\\; a_{1}\\; \\cdots \\; a_{k-1}]\\begin{bmatrix}b_{0}\\\\ b_{1}\\\\ \\vdots \\\\ b_{k-1}\\end{bmatrix} = a_{0}^{T}b_{0}+a_{1}^{T}b_{1} + \\cdots + a_{k-1}^{T}b_{k-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Producto interno en Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sean $\\vec{a},\\vec{b}$ vectores en $\\mathbb{R}^{4}$. Diremos que los vectores son **ortogonales** o **perpendiculares** si $\\vec{a}\\cdot \\vec{b}= 0$\n",
    "\n",
    "Consideremos entonces $\\vec{a}=\\hat{e}_{0}$ y $\\vec{b} = \\hat{e}_{2}$. Vamos a realizar el producto punto en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,0,0,0]) #declaramos el vector e_1\n",
    "\n",
    "b = np.array([0,0,1,0]) #declaramos el vector e_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar el producto punto llamaremos a la función *numpy.dot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a,b> = 0\n"
     ]
    }
   ],
   "source": [
    "print('<a,b> =',np.dot(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera también podemos usar el operador $@$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a,b> = 0\n"
     ]
    }
   ],
   "source": [
    "print('<a,b> =',a.T@b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluación de polinomios**. Un polinomio de grado $n-1$ se puede expresar como $p(x) = c_{0} + c_{1}x + c_{2}x^{2} + \\cdots + c_{n-1}x^{n-1}$. Si consideramos los $n$-vectores $\\vec{c},\\vec{x}$ tales que:\n",
    "\n",
    "$$\n",
    "\\vec{c} = \\begin{bmatrix}c_{0}\\\\ c_{1}\\\\ \\vdots \\\\ c_{n-1}\\end{bmatrix},\\qquad \\vec{x}(x) = \\begin{bmatrix}x^{0}\\\\ x^{1}\\\\ \\vdots \\\\ x^{n-1}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Así pues, usando estos vectores es posible expresar $p(x) = \\vec{c}^{T}\\vec{x}(x)$. Un ejemplo más concreto sería $p(x)=1+2x$, usando los vectores:\n",
    "\n",
    "$$\n",
    "\\vec{c} = \\begin{bmatrix}1\\\\ 2 \\end{bmatrix}, \\qquad \\vec{x}(x) = \\begin{bmatrix}1\\\\ x \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Entonces podemos escribir:\n",
    "$$\n",
    "p(x) = \\vec{c}^{T}\\vec{x}(x) = [1 \\; 2] \\begin{bmatrix}1\\\\ x \\end{bmatrix} = 1\\cdot 1 + 2\\cdot x = 1 + 2x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así pues en Python podemos escribir el polinomio como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(x):\n",
    "    return np.array([1,2])@np.array([1,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(0) =  1\n",
      "p(1) =  3\n",
      "p(2) =  5\n"
     ]
    }
   ],
   "source": [
    "print('p(0) = ',p(0))\n",
    "print('p(1) = ',p(1))\n",
    "print('p(2) = ',p(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Ejercicios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema 1: Análisis de sentimientos de tweets.** Vamos a crear un máquina que pueda decirnos qué tan positivo, neutral o negativo son una serie de respuestas de twitter.  \n",
    "Las respuestas son:\n",
    "> Gran mexicano y excelente en su área, su muerte es una enorme perdida y debería ser luto nacional!!!\n",
    "\n",
    "> Vaya señora que bueno que se asesora por alguien inteligente no por el ignorante del Gatt.\n",
    "\n",
    "> Se me ocurre y sin ver todos los videos de Plazti que me informéis por dónde empiezo. Entiendo que os tendría que decir quién soy y que quiero, vamos conocerme para asesorarme bien.\n",
    "Un saludo\n",
    "\n",
    "> Soy docente universitario, estoy intentando preparar mis clases en modo platzi bien didáctico, (le llamo modo noticiero), descargue una plataforma gratuita de grabación y transmisión de vídeo, se llama Obs estudio!bueno la sigo remando con sus funciones pero sé que saldrá algo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Gran mexicano y excelente en su área, su muerte es una enorme perdida y debería ser luto nacional!!!\"\n",
    "a = a.replace(\"!\",\"\").replace(\",\",\"\").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gran',\n",
       " 'mexicano',\n",
       " 'y',\n",
       " 'excelente',\n",
       " 'en',\n",
       " 'su',\n",
       " 'área',\n",
       " 'su',\n",
       " 'muerte',\n",
       " 'es',\n",
       " 'una',\n",
       " 'enorme',\n",
       " 'perdida',\n",
       " 'y',\n",
       " 'debería',\n",
       " 'ser',\n",
       " 'luto',\n",
       " 'nacional']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sí\n"
     ]
    }
   ],
   "source": [
    "if 'muerte' in a:\n",
    "    print(\"Sí\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, no podemos sacar toda la información de los textos sino vamos a buscar cadenas (strings) específicas. Así pues vamos a construir una función de Python que cuente la cantidad de veces que aparece cierta cadena. Como ejemplo, supongamos que las palabras que vamos a contar son *muerte*, *pérdida*, *luto*, *excelente*,*gran* y *positivo*, y además esto lo queremos expresar como vector en orden respectivo, así pues el primer comentario lo podemos expresar como el siguiente vector:\n",
    "$$\n",
    "\\vec{w} = \\begin{bmatrix}1\\\\ 1 \\\\ 1\\\\ 1\\\\ 1 \\\\0 \\end{bmatrix}\n",
    "$$\n",
    "Ahora, vamos a crear otra función en la que tendremos el vector con entradas de cantidad de palabras positivas, negativas y neutras. Siguiendo con el ejemplo vamos a sumar un uno a la primer entrada si aparece alguna de las siguientes palabras *excelente*,*gran* y *positivo*, un uno en la segunda por cada vez que aparezca la palabra *pérdida* y un uno a la última entrada si aparecen las palabras *muerte* y *luto*. Así pues, el primer twett lo podemos representar como:\n",
    "\n",
    "$$\n",
    "\\vec{s} = \\begin{bmatrix} 2 \\\\ 1 \\\\2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Ahora, para ver la *calidad* del resultado que tendremos para un twett conviene calcular el promedio de las entradas de un vector de palabras\n",
    "$$avg(\\vec{w}) = (\\mathbf{1}/n)^{T}\\vec{w}$$\n",
    "Y después calcularás el promedio del sentimiento de cada tweet $avg(\\vec{s})$ y de igual manera el *score sentimental* que se define como \n",
    "$$score(\\vec{s}) = [1\\; 0\\; -1] \\begin{bmatrix} s_{0} \\\\ s_{1} \\\\s_{2} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leyendo los tuits decide el conjunto mínimo de palabras que vas a contar en todos los tuits, solamente deberás hacer una función para contar palabras para todos los tuits, no hagas un función por enunciado. Según tu esquema reponde lo siguiente:\n",
    "\n",
    "* ¿Qué tuit es más positivo?\n",
    "\n",
    "* ¿Qué tuit es más negativo?\n",
    "\n",
    "* ¿Cuál es tu calidad promedio?\n",
    "\n",
    "* ¿Cómo interpretas $avg(\\vec{s})$ y $score(\\vec{s})$?\n",
    "\n",
    "* ¿Cómo relacionas la calidad con $score(\\vec{s})$ y $avg(\\vec{s})$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
